#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
æ™ºèƒ½ä»»åŠ¡åˆ†è§£ç³»ç»Ÿ
ç”¨é€”ï¼šè‡ªåŠ¨ä»»åŠ¡åˆ†è§£å’Œä¾èµ–ç®¡ç†
"""

import json
import re
from datetime import datetime
from pathlib import Path
from collections import defaultdict, deque

# å·¥ä½œç›®å½•
BASE_DIR = Path(__file__).parent.parent
TASK_FILE = BASE_DIR / "å·¥ä½œè®°å½•ç³»ç»Ÿ" / "ä»»åŠ¡æ¸…å•.md"
DECOMPOSITION_FILE = BASE_DIR / "å·¥ä½œè®°å½•ç³»ç»Ÿ" / "ä»»åŠ¡åˆ†è§£è®°å½•.md"


def read_tasks():
    """è¯»å–ä»»åŠ¡æ¸…å•"""
    if not TASK_FILE.exists():
        return None
    with open(TASK_FILE, 'r', encoding='utf-8') as f:
        return f.read()


def identify_task_type(task_description):
    """è¯†åˆ«ä»»åŠ¡ç±»åž‹"""
    task_lower = task_description.lower()
    
    # æ£€æŸ¥ç±»ä»»åŠ¡
    if any(keyword in task_lower for keyword in ['æ£€æŸ¥', 'å®¡æŸ¥', 'éªŒè¯', 'å®¡æ ¸']):
        return 'æ£€æŸ¥'
    
    # ä¿®å¤ç±»ä»»åŠ¡
    if any(keyword in task_lower for keyword in ['ä¿®å¤', 'æ›´æ–°', 'åˆ é™¤', 'å½’æ¡£']):
        return 'ä¿®å¤'
    
    # åˆ›å»ºç±»ä»»åŠ¡
    if any(keyword in task_lower for keyword in ['åˆ›å»º', 'å»ºç«‹', 'ç”Ÿæˆ', 'åˆ¶ä½œ']):
        return 'åˆ›å»º'
    
    # ä¼˜åŒ–ç±»ä»»åŠ¡
    if any(keyword in task_lower for keyword in ['ä¼˜åŒ–', 'æ”¹è¿›', 'æå‡', 'å¢žå¼º']):
        return 'ä¼˜åŒ–'
    
    return 'å…¶ä»–'


def decompose_task(task_description, task_type):
    """åˆ†è§£ä»»åŠ¡ä¸ºå­ä»»åŠ¡"""
    subtasks = []
    
    if task_type == 'æ£€æŸ¥':
        subtasks = [
            'å‡†å¤‡æ£€æŸ¥æ¸…å•',
            'æ‰§è¡Œæ£€æŸ¥',
            'è®°å½•æ£€æŸ¥ç»“æžœ',
            'ç”Ÿæˆæ£€æŸ¥æŠ¥å‘Š'
        ]
    
    elif task_type == 'ä¿®å¤':
        subtasks = [
            'è¯†åˆ«é—®é¢˜',
            'åˆ¶å®šä¿®å¤æ–¹æ¡ˆ',
            'æ‰§è¡Œä¿®å¤',
            'éªŒè¯ä¿®å¤æ•ˆæžœ'
        ]
    
    elif task_type == 'åˆ›å»º':
        subtasks = [
            'è®¾è®¡ç»“æž„',
            'åˆ›å»ºå†…å®¹',
            'æ£€æŸ¥è´¨é‡',
            'å®Œæˆæ–‡æ¡£'
        ]
    
    elif task_type == 'ä¼˜åŒ–':
        subtasks = [
            'åˆ†æžçŽ°çŠ¶',
            'åˆ¶å®šä¼˜åŒ–æ–¹æ¡ˆ',
            'å®žæ–½ä¼˜åŒ–',
            'éªŒè¯æ•ˆæžœ'
        ]
    
    else:
        subtasks = [
            'åˆ†æžéœ€æ±‚',
            'åˆ¶å®šæ–¹æ¡ˆ',
            'æ‰§è¡Œä»»åŠ¡',
            'éªŒè¯ç»“æžœ'
        ]
    
    return subtasks


def extract_task_dependencies(task_content):
    """æå–ä»»åŠ¡ä¾èµ–å…³ç³»"""
    dependencies = {}
    
    if not task_content:
        return dependencies
    
    # æå–æ‰€æœ‰ä»»åŠ¡
    pattern = r'### (TASK-\d+):(.*?)\n((?:- \*\*.*?\*\*ï¼š.*?\n)*)'
    matches = re.findall(pattern, task_content, re.DOTALL)
    
    for task_id, desc, details in matches:
        # æå–ä¾èµ–ä»»åŠ¡
        dep_match = re.search(r'- \*\*ä¾èµ–ä»»åŠ¡\*\*ï¼š(.*?)\n', details)
        if dep_match:
            dep_str = dep_match.group(1).strip()
            if dep_str and dep_str != 'æ— ':
                deps = [d.strip() for d in dep_str.split('ã€') if d.strip()]
                dependencies[task_id] = {
                    'description': desc.strip(),
                    'dependencies': deps
                }
            else:
                dependencies[task_id] = {
                    'description': desc.strip(),
                    'dependencies': []
                }
        else:
            dependencies[task_id] = {
                'description': desc.strip(),
                'dependencies': []
            }
    
    return dependencies


def build_dependency_graph(dependencies):
    """æž„å»ºä¾èµ–å›¾"""
    graph = defaultdict(list)
    in_degree = defaultdict(int)
    
    # åˆå§‹åŒ–æ‰€æœ‰ä»»åŠ¡
    for task_id in dependencies:
        in_degree[task_id] = 0
    
    # æž„å»ºå›¾
    for task_id, info in dependencies.items():
        for dep in info['dependencies']:
            if dep in dependencies:
                graph[dep].append(task_id)
                in_degree[task_id] += 1
    
    return graph, in_degree


def find_critical_path(dependencies, graph, in_degree):
    """æ‰¾åˆ°å…³é”®è·¯å¾„"""
    # ä½¿ç”¨æ‹“æ‰‘æŽ’åºæ‰¾åˆ°æœ€é•¿è·¯å¾„
    queue = deque()
    dist = {}
    
    # åˆå§‹åŒ–è·ç¦»
    for task_id in dependencies:
        if in_degree[task_id] == 0:
            queue.append(task_id)
            dist[task_id] = 1
        else:
            dist[task_id] = 0
    
    # BFSè®¡ç®—æœ€é•¿è·¯å¾„
    while queue:
        current = queue.popleft()
        for neighbor in graph[current]:
            in_degree[neighbor] -= 1
            dist[neighbor] = max(dist[neighbor], dist[current] + 1)
            if in_degree[neighbor] == 0:
                queue.append(neighbor)
    
    # æ‰¾åˆ°æœ€é•¿è·¯å¾„
    max_dist = max(dist.values()) if dist else 0
    critical_tasks = [task_id for task_id, d in dist.items() if d == max_dist]
    
    return critical_tasks, max_dist


def identify_parallel_tasks(dependencies):
    """è¯†åˆ«å¯å¹¶è¡Œæ‰§è¡Œçš„ä»»åŠ¡"""
    graph, in_degree = build_dependency_graph(dependencies)
    
    # æ‰¾åˆ°æ‰€æœ‰æ²¡æœ‰ä¾èµ–çš„ä»»åŠ¡ï¼ˆå¯ä»¥å¹¶è¡Œæ‰§è¡Œï¼‰
    parallel_groups = []
    current_level = [task_id for task_id, degree in in_degree.items() if degree == 0]
    
    if current_level:
        parallel_groups.append(current_level)
    
    # ä½¿ç”¨æ‹“æ‰‘æŽ’åºæ‰¾åˆ°æ¯ä¸€å±‚çš„ä»»åŠ¡
    temp_in_degree = in_degree.copy()
    temp_graph = {k: v[:] for k, v in graph.items()}
    
    while current_level:
        next_level = []
        for task_id in current_level:
            for neighbor in temp_graph[task_id]:
                temp_in_degree[neighbor] -= 1
                if temp_in_degree[neighbor] == 0:
                    next_level.append(neighbor)
        
        if next_level:
            parallel_groups.append(next_level)
        current_level = next_level
    
    return parallel_groups


def optimize_execution_order(dependencies):
    """ä¼˜åŒ–æ‰§è¡Œé¡ºåº"""
    graph, in_degree = build_dependency_graph(dependencies)
    
    # æ‹“æ‰‘æŽ’åº
    queue = deque()
    for task_id, degree in in_degree.items():
        if degree == 0:
            queue.append(task_id)
    
    execution_order = []
    while queue:
        # åŒä¸€å±‚çš„ä»»åŠ¡å¯ä»¥å¹¶è¡Œæ‰§è¡Œ
        level_tasks = []
        level_size = len(queue)
        for _ in range(level_size):
            task_id = queue.popleft()
            level_tasks.append(task_id)
            execution_order.append(task_id)
            
            for neighbor in graph[task_id]:
                in_degree[neighbor] -= 1
                if in_degree[neighbor] == 0:
                    queue.append(neighbor)
        
        if level_tasks:
            execution_order.append(('parallel', level_tasks))
    
    return execution_order


def identify_blocked_tasks(dependencies, task_content):
    """è¯†åˆ«é˜»å¡žä»»åŠ¡"""
    blocked = []
    
    graph, in_degree = build_dependency_graph(dependencies)
    
    for task_id, info in dependencies.items():
        # æ£€æŸ¥ä¾èµ–ä»»åŠ¡æ˜¯å¦å®Œæˆ
        for dep_task in info['dependencies']:
            dep_status = get_task_status(task_content, dep_task)
            if dep_status and dep_status != 'å·²å®Œæˆ':
                blocked.append({
                    'task_id': task_id,
                    'description': info['description'],
                    'blocked_by': dep_task,
                    'reason': f'ä¾èµ–ä»»åŠ¡ {dep_task} æœªå®Œæˆ'
                })
    
    return blocked


def get_task_status(task_content, task_id):
    """èŽ·å–ä»»åŠ¡çŠ¶æ€"""
    if not task_content:
        return None
    
    pattern = rf'### {re.escape(task_id)}:.*?\n((?:- \*\*.*?\*\*ï¼š.*?\n)*)'
    match = re.search(pattern, task_content)
    if match:
        status_match = re.search(r'- \*\*çŠ¶æ€\*\*ï¼š(.*?)\n', match.group(1))
        if status_match:
            return status_match.group(1).strip()
    return None


def decompose_and_analyze(task_description=None, task_id=None):
    """åˆ†è§£ä»»åŠ¡å¹¶åˆ†æž"""
    print("ðŸ” å¼€å§‹ä»»åŠ¡åˆ†è§£å’Œåˆ†æž...")
    
    # è¯»å–ä»»åŠ¡æ¸…å•
    task_content = read_tasks()
    
    if not task_content:
        print("âŒ é”™è¯¯ï¼šæ‰¾ä¸åˆ°ä»»åŠ¡æ¸…å•æ–‡ä»¶")
        return None
    
    # å¦‚æžœæä¾›äº†ä»»åŠ¡æè¿°ï¼Œåˆ†è§£æ–°ä»»åŠ¡
    if task_description:
        task_type = identify_task_type(task_description)
        subtasks = decompose_task(task_description, task_type)
        
        print(f"\nðŸ“‹ ä»»åŠ¡åˆ†è§£ç»“æžœï¼š{task_description}")
        print(f"   ä»»åŠ¡ç±»åž‹ï¼š{task_type}")
        print(f"   å­ä»»åŠ¡æ•°é‡ï¼š{len(subtasks)}")
        for i, subtask in enumerate(subtasks, 1):
            print(f"   {i}. {subtask}")
        
        return {
            'task_description': task_description,
            'task_type': task_type,
            'subtasks': subtasks
        }
    
    # åˆ†æžçŽ°æœ‰ä»»åŠ¡çš„ä¾èµ–å…³ç³»
    print("\nðŸ“Š åˆ†æžä»»åŠ¡ä¾èµ–å…³ç³»...")
    dependencies = extract_task_dependencies(task_content)
    print(f"   å‘çŽ° {len(dependencies)} ä¸ªä»»åŠ¡")
    
    # æž„å»ºä¾èµ–å›¾
    print("\nðŸ“Š æž„å»ºä¾èµ–å›¾...")
    graph, in_degree = build_dependency_graph(dependencies)
    print(f"   ä¾èµ–å›¾æž„å»ºå®Œæˆ")
    
    # æ‰¾åˆ°å…³é”®è·¯å¾„
    print("\nðŸ“Š æŸ¥æ‰¾å…³é”®è·¯å¾„...")
    critical_tasks, critical_length = find_critical_path(dependencies, graph, in_degree)
    print(f"   å…³é”®è·¯å¾„é•¿åº¦ï¼š{critical_length}")
    print(f"   å…³é”®ä»»åŠ¡ï¼š{', '.join(critical_tasks[:5])}")
    
    # è¯†åˆ«å¯å¹¶è¡Œæ‰§è¡Œçš„ä»»åŠ¡
    print("\nðŸ“Š è¯†åˆ«å¯å¹¶è¡Œæ‰§è¡Œçš„ä»»åŠ¡...")
    parallel_groups = identify_parallel_tasks(dependencies)
    print(f"   å‘çŽ° {len(parallel_groups)} ä¸ªå¹¶è¡Œç»„")
    for i, group in enumerate(parallel_groups[:3], 1):
        print(f"   å¹¶è¡Œç»„{i}ï¼š{len(group)}ä¸ªä»»åŠ¡å¯ä»¥å¹¶è¡Œæ‰§è¡Œ")
    
    # ä¼˜åŒ–æ‰§è¡Œé¡ºåº
    print("\nðŸ“Š ä¼˜åŒ–æ‰§è¡Œé¡ºåº...")
    execution_order = optimize_execution_order(dependencies)
    
    # è¯†åˆ«é˜»å¡žä»»åŠ¡
    print("\nðŸ“Š è¯†åˆ«é˜»å¡žä»»åŠ¡...")
    blocked_tasks = identify_blocked_tasks(dependencies, task_content)
    print(f"   å‘çŽ° {len(blocked_tasks)} ä¸ªé˜»å¡žä»»åŠ¡")
    
    # ç”ŸæˆæŠ¥å‘Š
    report = generate_decomposition_report(
        dependencies, critical_tasks, critical_length,
        parallel_groups, execution_order, blocked_tasks
    )
    
    # ä¿å­˜æŠ¥å‘Š
    save_decomposition_report(report)
    
    return {
        'dependencies': dependencies,
        'critical_tasks': critical_tasks,
        'critical_length': critical_length,
        'parallel_groups': parallel_groups,
        'execution_order': execution_order,
        'blocked_tasks': blocked_tasks,
        'report': report
    }


def generate_decomposition_report(dependencies, critical_tasks, critical_length,
                                  parallel_groups, execution_order, blocked_tasks):
    """ç”Ÿæˆåˆ†è§£æŠ¥å‘Š"""
    report = "# æ™ºèƒ½ä»»åŠ¡åˆ†è§£æŠ¥å‘Š\n\n"
    report += f"## ã€å…ƒæ•°æ®ã€‘\n"
    report += f"- **åˆ†è§£æ—¶é—´**ï¼š{datetime.now().strftime('%Y-%m-%d %H:%M')}\n"
    report += f"- **ä»»åŠ¡æ€»æ•°**ï¼š{len(dependencies)}ä¸ª\n"
    report += f"- **ç‰ˆæœ¬**ï¼šV1.0\n\n"
    report += "---\n\n"
    
    # ä¾èµ–å…³ç³»
    report += "## ðŸ“Š ä»»åŠ¡ä¾èµ–å…³ç³»\n\n"
    report += f"**æ€»ä»»åŠ¡æ•°**ï¼š{len(dependencies)}ä¸ª\n"
    report += f"**æœ‰ä¾èµ–å…³ç³»çš„ä»»åŠ¡**ï¼š{len([d for d in dependencies.values() if d['dependencies']])}ä¸ª\n\n"
    
    # å…³é”®è·¯å¾„
    report += "## ðŸŽ¯ å…³é”®è·¯å¾„\n\n"
    report += f"**å…³é”®è·¯å¾„é•¿åº¦**ï¼š{critical_length}ä¸ªä»»åŠ¡\n"
    report += f"**å…³é”®ä»»åŠ¡**ï¼š\n"
    for task_id in critical_tasks[:10]:
        desc = dependencies[task_id]['description']
        report += f"- `{task_id}`: {desc}\n"
    report += "\n"
    
    # å¹¶è¡Œæ‰§è¡Œ
    report += "## âš¡ å¯å¹¶è¡Œæ‰§è¡Œçš„ä»»åŠ¡\n\n"
    report += f"**å¹¶è¡Œç»„æ•°**ï¼š{len(parallel_groups)}ä¸ª\n\n"
    for i, group in enumerate(parallel_groups[:5], 1):
        report += f"### å¹¶è¡Œç»„{i}ï¼ˆ{len(group)}ä¸ªä»»åŠ¡ï¼‰\n"
        for task_id in group[:5]:
            desc = dependencies[task_id]['description']
            report += f"- `{task_id}`: {desc}\n"
        report += "\n"
    
    # é˜»å¡žä»»åŠ¡
    if blocked_tasks:
        report += "## âš ï¸ é˜»å¡žä»»åŠ¡\n\n"
        report += f"**é˜»å¡žä»»åŠ¡æ•°**ï¼š{len(blocked_tasks)}ä¸ª\n\n"
        for task in blocked_tasks[:5]:
            report += f"- `{task['task_id']}`: {task['description']}\n"
            report += f"  - é˜»å¡žåŽŸå› ï¼š{task['reason']}\n"
        report += "\n"
    
    # ä¼˜åŒ–åŽçš„æ‰§è¡Œé¡ºåº
    report += "## ðŸ”„ ä¼˜åŒ–åŽçš„æ‰§è¡Œé¡ºåº\n\n"
    report += "**å»ºè®®æ‰§è¡Œé¡ºåº**ï¼š\n\n"
    level = 1
    for item in execution_order[:20]:
        if isinstance(item, tuple) and item[0] == 'parallel':
            report += f"**ç¬¬{level}å±‚ï¼ˆå¯å¹¶è¡Œæ‰§è¡Œï¼‰**ï¼š\n"
            for task_id in item[1][:5]:
                desc = dependencies[task_id]['description']
                report += f"- `{task_id}`: {desc}\n"
            report += "\n"
            level += 1
        elif isinstance(item, str):
            desc = dependencies[item]['description']
            report += f"{level}. `{item}`: {desc}\n"
            level += 1
    
    report += "\n---\n\n"
    report += "**æœ€åŽæ›´æ–°**ï¼š" + datetime.now().strftime('%Y-%m-%d %H:%M') + "\n"
    
    return report


def save_decomposition_report(report):
    """ä¿å­˜åˆ†è§£æŠ¥å‘Š"""
    with open(DECOMPOSITION_FILE, 'w', encoding='utf-8') as f:
        f.write(report)
    
    print(f"\nâœ… å·²ä¿å­˜ä»»åŠ¡åˆ†è§£æŠ¥å‘Šï¼š{DECOMPOSITION_FILE}")


if __name__ == "__main__":
    import sys
    
    if len(sys.argv) > 1:
        task_description = sys.argv[1]
        decompose_and_analyze(task_description=task_description)
    else:
        decompose_and_analyze()

