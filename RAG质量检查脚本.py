#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
RAGçŸ¥è¯†åº“è´¨é‡æ£€æŸ¥è„šæœ¬
åŠŸèƒ½ï¼šè‡ªåŠ¨æ£€æŸ¥RAGçŸ¥è¯†åº“å†…å®¹è´¨é‡ï¼Œç”Ÿæˆè´¨é‡æŠ¥å‘Šå’Œä¿®å¤æ¸…å•
"""

import os
import re
from datetime import datetime
from pathlib import Path
from collections import defaultdict

# å·¥ä½œç›®å½•
BASE_DIR = Path(__file__).parent.parent
RAG_DIR = BASE_DIR / "RAGçŸ¥è¯†åº“"
OUTPUT_DIR = BASE_DIR / "å·¥ä½œè®°å½•ç³»ç»Ÿ"

# ç¦æ­¢çš„å ä½ç¬¦
FORBIDDEN_PLACEHOLDERS = [
    r'å¾…è¡¥å……',
    r'å¾…æ›´æ–°',
    r'å¾…å®¡æ ¸',
    r'å¾…ç¡®è®¤',
    r'\[å¾…è¡¥å……\]',
    r'\[å¾…æ›´æ–°\]',
    r'\[å¾…å®¡æ ¸\]',
    r'\[å¾…ç¡®è®¤\]',
    r'TBD',
    r'TODO',
    r'å¾…æ˜ç¡®',
    r'å¾…å®Œå–„',
]

# å…ƒæ•°æ®å¿…å¡«å­—æ®µ
METADATA_FIELDS = ['ç”¨é€”', 'æ›´æ–°æ—¥æœŸ', 'ç‰ˆæœ¬']


def find_md_files(directory):
    """æŸ¥æ‰¾æ‰€æœ‰Markdownæ–‡ä»¶"""
    md_files = []
    for root, dirs, files in os.walk(directory):
        # è·³è¿‡å½’æ¡£ç›®å½•
        if 'å½’æ¡£æ–‡ä»¶' in root or 'å½’æ¡£' in root:
            continue
        for file in files:
            if file.endswith('.md'):
                md_files.append(Path(root) / file)
    return md_files


def check_placeholders(file_path):
    """æ£€æŸ¥å ä½ç¬¦"""
    issues = []
    try:
        with open(file_path, 'r', encoding='utf-8') as f:
            content = f.read()
            lines = content.split('\n')
            
            for i, line in enumerate(lines, 1):
                for pattern in FORBIDDEN_PLACEHOLDERS:
                    if re.search(pattern, line, re.IGNORECASE):
                        issues.append({
                            'line': i,
                            'content': line.strip(),
                            'pattern': pattern
                        })
    except Exception as e:
        issues.append({
            'line': 0,
            'content': f'è¯»å–æ–‡ä»¶å¤±è´¥: {e}',
            'pattern': 'FILE_ERROR'
        })
    
    return issues


def check_metadata(file_path):
    """æ£€æŸ¥å…ƒæ•°æ®å®Œæ•´æ€§"""
    issues = []
    try:
        with open(file_path, 'r', encoding='utf-8') as f:
            content = f.read()
            
            # æ£€æŸ¥æ˜¯å¦æœ‰å…ƒæ•°æ®éƒ¨åˆ†
            if '## ã€å…ƒæ•°æ®ã€‘' not in content and '## å…ƒæ•°æ®' not in content:
                issues.append({
                    'type': 'missing_metadata',
                    'message': 'ç¼ºå°‘å…ƒæ•°æ®éƒ¨åˆ†'
                })
                return issues
            
            # æ£€æŸ¥å¿…å¡«å­—æ®µ
            for field in METADATA_FIELDS:
                pattern = rf'\*\*{field}\*\*'
                if not re.search(pattern, content):
                    issues.append({
                        'type': 'missing_field',
                        'field': field,
                        'message': f'ç¼ºå°‘å…ƒæ•°æ®å­—æ®µ: {field}'
                    })
            
            # æ£€æŸ¥æ›´æ–°æ—¥æœŸæ˜¯å¦è¿‡æ—¶ï¼ˆè¶…è¿‡30å¤©ï¼‰
            date_pattern = r'\*\*æ›´æ–°æ—¥æœŸ\*\*[ï¼š:]\s*(\d{4}-\d{2}-\d{2})'
            match = re.search(date_pattern, content)
            if match:
                update_date_str = match.group(1)
                try:
                    update_date = datetime.strptime(update_date_str, '%Y-%m-%d')
                    days_old = (datetime.now() - update_date).days
                    if days_old > 30:
                        issues.append({
                            'type': 'outdated_date',
                            'date': update_date_str,
                            'days_old': days_old,
                            'message': f'æ›´æ–°æ—¥æœŸè¿‡æ—¶: {update_date_str} (å·²è¿‡{days_old}å¤©)'
                        })
                except ValueError:
                    issues.append({
                        'type': 'invalid_date',
                        'date': update_date_str,
                        'message': f'æ›´æ–°æ—¥æœŸæ ¼å¼é”™è¯¯: {update_date_str}'
                    })
    except Exception as e:
        issues.append({
            'type': 'read_error',
            'message': f'è¯»å–æ–‡ä»¶å¤±è´¥: {e}'
        })
    
    return issues


def check_file_references(file_path, all_files):
    """æ£€æŸ¥æ–‡ä»¶å¼•ç”¨"""
    issues = []
    try:
        with open(file_path, 'r', encoding='utf-8') as f:
            content = f.read()
            
            # æŸ¥æ‰¾æ–‡ä»¶å¼•ç”¨ï¼ˆ@ç¬¦å·æˆ–æ–‡ä»¶è·¯å¾„ï¼‰
            # åŒ¹é… @æ–‡ä»¶å.md æˆ– `è·¯å¾„/æ–‡ä»¶å.md`
            ref_patterns = [
                r'@([^\s]+\.md)',
                r'`([^\s`]+\.md)`',
                r'\[([^\]]+\.md)\]',
            ]
            
            referenced_files = set()
            for pattern in ref_patterns:
                matches = re.findall(pattern, content)
                for match in matches:
                    referenced_files.add(match)
            
            # æ£€æŸ¥å¼•ç”¨çš„æ–‡ä»¶æ˜¯å¦å­˜åœ¨
            file_dir = file_path.parent
            for ref_file in referenced_files:
                # å°è¯•å¤šç§è·¯å¾„è§£ææ–¹å¼
                ref_paths = [
                    file_dir / ref_file,
                    RAG_DIR / ref_file,
                    RAG_DIR / ref_file.split('/')[-1],  # åªå–æ–‡ä»¶å
                ]
                
                found = False
                for ref_path in ref_paths:
                    if ref_path.exists() and ref_path in all_files:
                        found = True
                        break
                
                if not found:
                    issues.append({
                        'type': 'missing_reference',
                        'file': ref_file,
                        'message': f'å¼•ç”¨çš„æ–‡ä»¶ä¸å­˜åœ¨: {ref_file}'
                    })
    except Exception as e:
        issues.append({
            'type': 'read_error',
            'message': f'è¯»å–æ–‡ä»¶å¤±è´¥: {e}'
        })
    
    return issues


def check_business_logic(file_path):
    """æ£€æŸ¥ä¸šåŠ¡é€»è¾‘"""
    issues = []
    try:
        with open(file_path, 'r', encoding='utf-8') as f:
            content = f.read()
            
            # æ£€æŸ¥æ—¶é—´è½´é€»è¾‘é”™è¯¯ï¼ˆå¦‚"21:00-21:00"ï¼‰
            time_pattern = r'(\d{1,2}):(\d{2})-(\d{1,2}):(\d{2})'
            matches = re.findall(time_pattern, content)
            for match in matches:
                start_hour, start_min = int(match[0]), int(match[1])
                end_hour, end_min = int(match[2]), int(match[3])
                
                start_time = start_hour * 60 + start_min
                end_time = end_hour * 60 + end_min
                
                if start_time >= end_time:
                    time_str = f"{match[0]}:{match[1]}-{match[2]}:{match[3]}"
                    issues.append({
                        'type': 'time_logic_error',
                        'time': time_str,
                        'message': f'æ—¶é—´è½´é€»è¾‘é”™è¯¯: {time_str} (ç»“æŸæ—¶é—´åº”æ™šäºå¼€å§‹æ—¶é—´)'
                    })
            
            # æ£€æŸ¥ä»·æ ¼ä¸€è‡´æ€§ï¼ˆç®€åŒ–æ£€æŸ¥ï¼‰
            price_patterns = [
                r'12\.9[å…ƒå—]',
                r'12980[å…ƒå—]',
                r'16980[å…ƒå—]',
            ]
            # è¿™é‡Œå¯ä»¥æ·»åŠ æ›´å¤æ‚çš„ä»·æ ¼ä¸€è‡´æ€§æ£€æŸ¥
            
    except Exception as e:
        issues.append({
            'type': 'read_error',
            'message': f'è¯»å–æ–‡ä»¶å¤±è´¥: {e}'
        })
    
    return issues


def check_version_conflicts(file_path, all_files):
    """æ£€æŸ¥ç‰ˆæœ¬å†²çª"""
    issues = []
    file_name = file_path.name
    
    # æ£€æŸ¥æ˜¯å¦æœ‰å¤šä¸ªç‰ˆæœ¬çš„æ–‡ä»¶
    if '_V' in file_name or '_v' in file_name:
        # æå–åŸºç¡€æ–‡ä»¶åï¼ˆå»æ‰ç‰ˆæœ¬å·ï¼‰
        base_name = re.sub(r'_[Vv]\d+\.\d+.*', '', file_name)
        base_name = re.sub(r'_\d+\.\d+.*', '', base_name)
        
        # æŸ¥æ‰¾åŒä¸€ç›®å½•ä¸‹çš„å…¶ä»–ç‰ˆæœ¬
        same_dir = file_path.parent
        for other_file in same_dir.glob('*.md'):
            if other_file != file_path:
                other_name = other_file.name
                if base_name in other_name or other_name.startswith(base_name.split('_')[0]):
                    issues.append({
                        'type': 'version_conflict',
                        'conflict_file': other_file.name,
                        'message': f'å¯èƒ½å­˜åœ¨ç‰ˆæœ¬å†²çª: {file_name} å’Œ {other_file.name}'
                    })
    
    return issues


def generate_quality_report(issues_by_file, all_files):
    """ç”Ÿæˆè´¨é‡æŠ¥å‘Š"""
    now = datetime.now()
    date_str = now.strftime('%Y-%m-%d')
    time_str = now.strftime('%Y-%m-%d %H:%M')
    
    # ç»Ÿè®¡é—®é¢˜
    total_files = len(all_files)
    files_with_issues = len(issues_by_file)
    total_issues = sum(len(issues) for issues in issues_by_file.values())
    
    # æŒ‰ä¼˜å…ˆçº§åˆ†ç±»é—®é¢˜
    p0_issues = []  # å ä½ç¬¦ã€ä¸šåŠ¡é€»è¾‘é”™è¯¯
    p1_issues = []  # å…ƒæ•°æ®ã€æ–‡ä»¶å¼•ç”¨
    p2_issues = []  # ç‰ˆæœ¬å†²çªã€æ—¥æœŸè¿‡æ—¶
    
    for file_path, issues in issues_by_file.items():
        rel_path = file_path.relative_to(BASE_DIR)
        for issue in issues:
            issue_entry = {
                'file': str(rel_path),
                'issue': issue
            }
            
            if issue.get('pattern') or issue.get('type') == 'time_logic_error':
                p0_issues.append(issue_entry)
            elif issue.get('type') in ['missing_metadata', 'missing_field', 'missing_reference']:
                p1_issues.append(issue_entry)
            else:
                p2_issues.append(issue_entry)
    
    report = f"""# RAGçŸ¥è¯†åº“è´¨é‡æ£€æŸ¥æŠ¥å‘Š

## ã€å…ƒæ•°æ®ã€‘
- **æ£€æŸ¥æ—¥æœŸ**ï¼š{time_str}
- **æ£€æŸ¥èŒƒå›´**ï¼šRAGçŸ¥è¯†åº“æ‰€æœ‰æ–‡ä»¶
- **æ€»æ–‡ä»¶æ•°**ï¼š{total_files}ä¸ª
- **æœ‰é—®é¢˜æ–‡ä»¶æ•°**ï¼š{files_with_issues}ä¸ª
- **æ€»é—®é¢˜æ•°**ï¼š{total_issues}ä¸ª
- **ç‰ˆæœ¬**ï¼šV1.0

---

## ğŸ“Š æ£€æŸ¥ç»Ÿè®¡

### æ€»ä½“æƒ…å†µ
- **æ€»æ–‡ä»¶æ•°**ï¼š{total_files}ä¸ª
- **æœ‰é—®é¢˜æ–‡ä»¶æ•°**ï¼š{files_with_issues}ä¸ª
- **é—®é¢˜æ–‡ä»¶å æ¯”**ï¼š{files_with_issues/total_files*100:.1f}%
- **æ€»é—®é¢˜æ•°**ï¼š{total_issues}ä¸ª
- **å¹³å‡æ¯æ–‡ä»¶é—®é¢˜æ•°**ï¼š{total_issues/total_files:.2f}ä¸ª

### é—®é¢˜åˆ†å¸ƒ
- **P0çº§åˆ«ï¼ˆä¸¥é‡ï¼‰**ï¼š{len(p0_issues)}ä¸ª
- **P1çº§åˆ«ï¼ˆé‡è¦ï¼‰**ï¼š{len(p1_issues)}ä¸ª
- **P2çº§åˆ«ï¼ˆä¸­ç­‰ï¼‰**ï¼š{len(p2_issues)}ä¸ª

---

## ğŸš¨ P0çº§åˆ«é—®é¢˜ï¼ˆç«‹å³ä¿®å¤ï¼‰

### å ä½ç¬¦é—®é¢˜
"""
    
    # æ·»åŠ P0çº§åˆ«é—®é¢˜
    placeholder_issues = [i for i in p0_issues if i['issue'].get('pattern')]
    if placeholder_issues:
        report += f"\n**å‘ç° {len(placeholder_issues)} ä¸ªå ä½ç¬¦é—®é¢˜ï¼š**\n\n"
        for entry in placeholder_issues[:20]:  # åªæ˜¾ç¤ºå‰20ä¸ª
            issue = entry['issue']
            report += f"- **æ–‡ä»¶**ï¼š`{entry['file']}`\n"
            if issue.get('line'):
                report += f"  - **è¡Œå·**ï¼š{issue['line']}\n"
            report += f"  - **é—®é¢˜**ï¼š{issue.get('content', issue.get('pattern', ''))}\n"
            report += f"  - **ç±»å‹**ï¼šå ä½ç¬¦\n\n"
    else:
        report += "\nâœ… æœªå‘ç°å ä½ç¬¦é—®é¢˜\n\n"
    
    # ä¸šåŠ¡é€»è¾‘é”™è¯¯
    logic_issues = [i for i in p0_issues if i['issue'].get('type') == 'time_logic_error']
    if logic_issues:
        report += f"\n### ä¸šåŠ¡é€»è¾‘é”™è¯¯\n\n"
        report += f"**å‘ç° {len(logic_issues)} ä¸ªä¸šåŠ¡é€»è¾‘é”™è¯¯ï¼š**\n\n"
        for entry in logic_issues[:10]:
            issue = entry['issue']
            report += f"- **æ–‡ä»¶**ï¼š`{entry['file']}`\n"
            report += f"  - **é—®é¢˜**ï¼š{issue.get('message', '')}\n\n"
    else:
        report += "\n### ä¸šåŠ¡é€»è¾‘é”™è¯¯\n\nâœ… æœªå‘ç°ä¸šåŠ¡é€»è¾‘é”™è¯¯\n\n"
    
    # æ·»åŠ P1çº§åˆ«é—®é¢˜
    report += f"""---

## âš ï¸ P1çº§åˆ«é—®é¢˜ï¼ˆæœ¬å‘¨ä¿®å¤ï¼‰

### å…ƒæ•°æ®é—®é¢˜
"""
    
    metadata_issues = [i for i in p1_issues if 'metadata' in i['issue'].get('type', '') or 'field' in i['issue'].get('type', '')]
    if metadata_issues:
        report += f"\n**å‘ç° {len(metadata_issues)} ä¸ªå…ƒæ•°æ®é—®é¢˜ï¼š**\n\n"
        for entry in metadata_issues[:15]:
            issue = entry['issue']
            report += f"- **æ–‡ä»¶**ï¼š`{entry['file']}`\n"
            report += f"  - **é—®é¢˜**ï¼š{issue.get('message', '')}\n\n"
    else:
        report += "\nâœ… æœªå‘ç°å…ƒæ•°æ®é—®é¢˜\n\n"
    
    # æ–‡ä»¶å¼•ç”¨é—®é¢˜
    ref_issues = [i for i in p1_issues if i['issue'].get('type') == 'missing_reference']
    if ref_issues:
        report += f"\n### æ–‡ä»¶å¼•ç”¨é—®é¢˜\n\n"
        report += f"**å‘ç° {len(ref_issues)} ä¸ªæ–‡ä»¶å¼•ç”¨é—®é¢˜ï¼š**\n\n"
        for entry in ref_issues[:15]:
            issue = entry['issue']
            report += f"- **æ–‡ä»¶**ï¼š`{entry['file']}`\n"
            report += f"  - **é—®é¢˜**ï¼š{issue.get('message', '')}\n\n"
    else:
        report += "\n### æ–‡ä»¶å¼•ç”¨é—®é¢˜\n\nâœ… æœªå‘ç°æ–‡ä»¶å¼•ç”¨é—®é¢˜\n\n"
    
    # æ·»åŠ P2çº§åˆ«é—®é¢˜
    report += f"""---

## ğŸ“‹ P2çº§åˆ«é—®é¢˜ï¼ˆæœ¬æœˆä¿®å¤ï¼‰

### ç‰ˆæœ¬å†²çª
"""
    
    version_issues = [i for i in p2_issues if i['issue'].get('type') == 'version_conflict']
    if version_issues:
        report += f"\n**å‘ç° {len(version_issues)} ä¸ªç‰ˆæœ¬å†²çªï¼š**\n\n"
        for entry in version_issues[:10]:
            issue = entry['issue']
            report += f"- **æ–‡ä»¶**ï¼š`{entry['file']}`\n"
            report += f"  - **é—®é¢˜**ï¼š{issue.get('message', '')}\n\n"
    else:
        report += "\nâœ… æœªå‘ç°ç‰ˆæœ¬å†²çª\n\n"
    
    # æ—¥æœŸè¿‡æ—¶é—®é¢˜
    date_issues = [i for i in p2_issues if i['issue'].get('type') == 'outdated_date']
    if date_issues:
        report += f"\n### æ›´æ–°æ—¥æœŸè¿‡æ—¶\n\n"
        report += f"**å‘ç° {len(date_issues)} ä¸ªæ—¥æœŸè¿‡æ—¶é—®é¢˜ï¼š**\n\n"
        for entry in date_issues[:10]:
            issue = entry['issue']
            report += f"- **æ–‡ä»¶**ï¼š`{entry['file']}`\n"
            report += f"  - **é—®é¢˜**ï¼š{issue.get('message', '')}\n\n"
    else:
        report += "\n### æ›´æ–°æ—¥æœŸè¿‡æ—¶\n\nâœ… æœªå‘ç°æ—¥æœŸè¿‡æ—¶é—®é¢˜\n\n"
    
    # æ·»åŠ ä¿®å¤æ¸…å•
    report += f"""---

## ğŸ“‹ ä¿®å¤æ¸…å•

### ç«‹å³ä¿®å¤ï¼ˆP0çº§åˆ«ï¼‰
"""
    
    if p0_issues:
        report += f"\n**å…± {len(p0_issues)} ä¸ªé—®é¢˜éœ€è¦ç«‹å³ä¿®å¤ï¼š**\n\n"
        for i, entry in enumerate(p0_issues[:10], 1):
            report += f"{i}. **æ–‡ä»¶**ï¼š`{entry['file']}`\n"
            report += f"   - **é—®é¢˜**ï¼š{entry['issue'].get('message', entry['issue'].get('content', ''))}\n"
            report += f"   - **ä¿®å¤å»ºè®®**ï¼šæ ¹æ®é—®é¢˜ç±»å‹è¿›è¡Œä¿®å¤\n\n"
    else:
        report += "\nâœ… æ— P0çº§åˆ«é—®é¢˜\n\n"
    
    report += f"""
### æœ¬å‘¨ä¿®å¤ï¼ˆP1çº§åˆ«ï¼‰
"""
    
    if p1_issues:
        report += f"\n**å…± {len(p1_issues)} ä¸ªé—®é¢˜éœ€è¦æœ¬å‘¨ä¿®å¤ï¼š**\n\n"
        for i, entry in enumerate(p1_issues[:10], 1):
            report += f"{i}. **æ–‡ä»¶**ï¼š`{entry['file']}`\n"
            report += f"   - **é—®é¢˜**ï¼š{entry['issue'].get('message', '')}\n\n"
    else:
        report += "\nâœ… æ— P1çº§åˆ«é—®é¢˜\n\n"
    
    report += f"""
### æœ¬æœˆä¿®å¤ï¼ˆP2çº§åˆ«ï¼‰
"""
    
    if p2_issues:
        report += f"\n**å…± {len(p2_issues)} ä¸ªé—®é¢˜éœ€è¦æœ¬æœˆä¿®å¤ï¼š**\n\n"
        for i, entry in enumerate(p2_issues[:10], 1):
            report += f"{i}. **æ–‡ä»¶**ï¼š`{entry['file']}`\n"
            report += f"   - **é—®é¢˜**ï¼š{entry['issue'].get('message', '')}\n\n"
    else:
        report += "\nâœ… æ— P2çº§åˆ«é—®é¢˜\n\n"
    
    # æ·»åŠ ä¿®å¤è¿›åº¦è·Ÿè¸ª
    report += f"""---

## ğŸ“ˆ ä¿®å¤è¿›åº¦è·Ÿè¸ª

### ä¿®å¤çŠ¶æ€
- **å¾…ä¿®å¤**ï¼š{total_issues}ä¸ª
- **å·²ä¿®å¤**ï¼š0ä¸ª
- **ä¿®å¤ç‡**ï¼š0%

### ä¿®å¤ä¼˜å…ˆçº§
1. **P0çº§åˆ«**ï¼š{len(p0_issues)}ä¸ªï¼ˆç«‹å³ä¿®å¤ï¼‰
2. **P1çº§åˆ«**ï¼š{len(p1_issues)}ä¸ªï¼ˆæœ¬å‘¨ä¿®å¤ï¼‰
3. **P2çº§åˆ«**ï¼š{len(p2_issues)}ä¸ªï¼ˆæœ¬æœˆä¿®å¤ï¼‰

---

## ğŸ“š ç›¸å…³æ–‡æ¡£

### è´¨é‡æ£€æŸ¥æ ‡å‡†
- `RAGçŸ¥è¯†åº“/00_è´¨é‡æ£€æŸ¥æœºåˆ¶.md` - è´¨é‡æ£€æŸ¥æœºåˆ¶
- `RAGçŸ¥è¯†åº“/15_ç›‘ç®¡Skillåº“/01_ç›‘ç®¡æ ‡å‡†Skill/01_è¯„åˆ†æ ‡å‡†.md` - è¯„åˆ†æ ‡å‡†

### ä¿®å¤æŒ‡å—
- `RAGçŸ¥è¯†åº“/00_è´¨é‡æ£€æŸ¥æœºåˆ¶.md` - ä¿®å¤æ ‡å‡†
- `RAGçŸ¥è¯†åº“ä¼˜åŒ–æ–¹æ¡ˆ.md` - ä¼˜åŒ–æ–¹æ¡ˆ

---

**æŠ¥å‘Šç”Ÿæˆæ—¶é—´**ï¼š{time_str}  
**ä¸‹æ¬¡æ£€æŸ¥æ—¶é—´**ï¼šä¸‹æ¬¡è¿è¡Œè„šæœ¬æ—¶
"""
    
    return report


def main():
    """ä¸»å‡½æ•°"""
    print("=" * 60)
    print("RAGçŸ¥è¯†åº“è´¨é‡æ£€æŸ¥è„šæœ¬")
    print("=" * 60)
    print()
    
    # æŸ¥æ‰¾æ‰€æœ‰Markdownæ–‡ä»¶
    print("ğŸ“– æ­£åœ¨æ‰«æRAGçŸ¥è¯†åº“æ–‡ä»¶...")
    all_files = find_md_files(RAG_DIR)
    print(f"   æ‰¾åˆ° {len(all_files)} ä¸ªMarkdownæ–‡ä»¶")
    
    # æ£€æŸ¥æ‰€æœ‰æ–‡ä»¶
    issues_by_file = defaultdict(list)
    
    print("\nğŸ” æ­£åœ¨æ£€æŸ¥æ–‡ä»¶è´¨é‡...")
    for i, file_path in enumerate(all_files, 1):
        if i % 10 == 0:
            print(f"   å·²æ£€æŸ¥ {i}/{len(all_files)} ä¸ªæ–‡ä»¶...")
        
        # æ£€æŸ¥å ä½ç¬¦
        placeholder_issues = check_placeholders(file_path)
        for issue in placeholder_issues:
            issues_by_file[file_path].append(issue)
        
        # æ£€æŸ¥å…ƒæ•°æ®
        metadata_issues = check_metadata(file_path)
        for issue in metadata_issues:
            issues_by_file[file_path].append(issue)
        
        # æ£€æŸ¥æ–‡ä»¶å¼•ç”¨
        ref_issues = check_file_references(file_path, all_files)
        for issue in ref_issues:
            issues_by_file[file_path].append(issue)
        
        # æ£€æŸ¥ä¸šåŠ¡é€»è¾‘
        logic_issues = check_business_logic(file_path)
        for issue in logic_issues:
            issues_by_file[file_path].append(issue)
        
        # æ£€æŸ¥ç‰ˆæœ¬å†²çª
        version_issues = check_version_conflicts(file_path, all_files)
        for issue in version_issues:
            issues_by_file[file_path].append(issue)
    
    # åªä¿ç•™æœ‰é—®é¢˜çš„æ–‡ä»¶
    issues_by_file = {k: v for k, v in issues_by_file.items() if v}
    
    print(f"\nâœ… æ£€æŸ¥å®Œæˆï¼å‘ç° {len(issues_by_file)} ä¸ªæ–‡ä»¶æœ‰é—®é¢˜")
    
    # ç”Ÿæˆè´¨é‡æŠ¥å‘Š
    print("\nğŸ“ æ­£åœ¨ç”Ÿæˆè´¨é‡æŠ¥å‘Š...")
    report = generate_quality_report(issues_by_file, all_files)
    
    # ä¿å­˜æŠ¥å‘Š
    now = datetime.now()
    date_str = now.strftime('%Y%m%d')
    report_file = OUTPUT_DIR / f"RAGçŸ¥è¯†åº“è´¨é‡æ£€æŸ¥æŠ¥å‘Š_{date_str}.md"
    
    try:
        with open(report_file, 'w', encoding='utf-8') as f:
            f.write(report)
        print(f"âœ… è´¨é‡æŠ¥å‘Šå·²ä¿å­˜ï¼š{report_file}")
    except Exception as e:
        print(f"âŒ ä¿å­˜æŠ¥å‘Šå¤±è´¥ï¼š{e}")
        return
    
    # ç”Ÿæˆä¿®å¤æ¸…å•
    print("\nğŸ“‹ æ­£åœ¨ç”Ÿæˆä¿®å¤æ¸…å•...")
    fix_list = generate_fix_list(issues_by_file)
    fix_list_file = OUTPUT_DIR / f"RAGçŸ¥è¯†åº“ä¿®å¤æ¸…å•_{date_str}.md"
    
    try:
        with open(fix_list_file, 'w', encoding='utf-8') as f:
            f.write(fix_list)
        print(f"âœ… ä¿®å¤æ¸…å•å·²ä¿å­˜ï¼š{fix_list_file}")
    except Exception as e:
        print(f"âŒ ä¿å­˜ä¿®å¤æ¸…å•å¤±è´¥ï¼š{e}")
    
    print("\n" + "=" * 60)
    print("âœ… RAGçŸ¥è¯†åº“è´¨é‡æ£€æŸ¥å®Œæˆï¼")
    print("=" * 60)
    print(f"\nğŸ“„ è´¨é‡æŠ¥å‘Šï¼š{report_file}")
    print(f"ğŸ“‹ ä¿®å¤æ¸…å•ï¼š{fix_list_file}")
    print(f"\nğŸ’¡ æç¤ºï¼šè¯·æ ¹æ®æŠ¥å‘Šä¼˜å…ˆçº§ä¿®å¤é—®é¢˜")


def generate_fix_list(issues_by_file):
    """ç”Ÿæˆä¿®å¤æ¸…å•"""
    now = datetime.now()
    date_str = now.strftime('%Y-%m-%d')
    
    # æŒ‰ä¼˜å…ˆçº§åˆ†ç±»
    p0_files = []
    p1_files = []
    p2_files = []
    
    for file_path, issues in issues_by_file.items():
        rel_path = file_path.relative_to(BASE_DIR)
        has_p0 = any(issue.get('pattern') or issue.get('type') == 'time_logic_error' for issue in issues)
        has_p1 = any(issue.get('type') in ['missing_metadata', 'missing_field', 'missing_reference'] for issue in issues)
        
        file_entry = {
            'path': str(rel_path),
            'issues': issues
        }
        
        if has_p0:
            p0_files.append(file_entry)
        elif has_p1:
            p1_files.append(file_entry)
        else:
            p2_files.append(file_entry)
    
    fix_list = f"""# RAGçŸ¥è¯†åº“ä¿®å¤æ¸…å•

## ã€å…ƒæ•°æ®ã€‘
- **ç”Ÿæˆæ—¥æœŸ**ï¼š{date_str}
- **ç‰ˆæœ¬**ï¼šV1.0
- **ç”¨é€”**ï¼šè·Ÿè¸ªRAGçŸ¥è¯†åº“è´¨é‡é—®é¢˜ä¿®å¤è¿›åº¦

---

## ğŸš¨ P0çº§åˆ«ä¿®å¤æ¸…å•ï¼ˆç«‹å³ä¿®å¤ï¼‰

### å ä½ç¬¦æ¸…ç†
"""
    
    placeholder_files = [f for f in p0_files if any(issue.get('pattern') for issue in f['issues'])]
    if placeholder_files:
        fix_list += f"\n**å…± {len(placeholder_files)} ä¸ªæ–‡ä»¶éœ€è¦æ¸…ç†å ä½ç¬¦ï¼š**\n\n"
        for i, file_entry in enumerate(placeholder_files, 1):
            fix_list += f"{i}. **æ–‡ä»¶**ï¼š`{file_entry['path']}`\n"
            placeholder_issues = [issue for issue in file_entry['issues'] if issue.get('pattern')]
            fix_list += f"   - **å ä½ç¬¦æ•°é‡**ï¼š{len(placeholder_issues)}ä¸ª\n"
            fix_list += f"   - **ä¿®å¤çŠ¶æ€**ï¼šå¾…ä¿®å¤\n"
            fix_list += f"   - **ä¿®å¤å»ºè®®**ï¼šé€ä¸€æ›¿æ¢å ä½ç¬¦ä¸ºå®é™…å†…å®¹\n\n"
    else:
        fix_list += "\nâœ… æ— å ä½ç¬¦é—®é¢˜\n\n"
    
    fix_list += f"""
### ä¸šåŠ¡é€»è¾‘é”™è¯¯ä¿®å¤
"""
    
    logic_files = [f for f in p0_files if any(issue.get('type') == 'time_logic_error' for issue in f['issues'])]
    if logic_files:
        fix_list += f"\n**å…± {len(logic_files)} ä¸ªæ–‡ä»¶éœ€è¦ä¿®å¤ä¸šåŠ¡é€»è¾‘é”™è¯¯ï¼š**\n\n"
        for i, file_entry in enumerate(logic_files, 1):
            fix_list += f"{i}. **æ–‡ä»¶**ï¼š`{file_entry['path']}`\n"
            logic_issues = [issue for issue in file_entry['issues'] if issue.get('type') == 'time_logic_error']
            fix_list += f"   - **é”™è¯¯æ•°é‡**ï¼š{len(logic_issues)}ä¸ª\n"
            fix_list += f"   - **ä¿®å¤çŠ¶æ€**ï¼šå¾…ä¿®å¤\n\n"
    else:
        fix_list += "\nâœ… æ— ä¸šåŠ¡é€»è¾‘é”™è¯¯\n\n"
    
    fix_list += f"""
---

## âš ï¸ P1çº§åˆ«ä¿®å¤æ¸…å•ï¼ˆæœ¬å‘¨ä¿®å¤ï¼‰

### å…ƒæ•°æ®è¡¥å……
"""
    
    metadata_files = [f for f in p1_files if any('metadata' in issue.get('type', '') or 'field' in issue.get('type', '') for issue in f['issues'])]
    if metadata_files:
        fix_list += f"\n**å…± {len(metadata_files)} ä¸ªæ–‡ä»¶éœ€è¦è¡¥å……å…ƒæ•°æ®ï¼š**\n\n"
        for i, file_entry in enumerate(metadata_files[:20], 1):
            fix_list += f"{i}. **æ–‡ä»¶**ï¼š`{file_entry['path']}`\n"
            fix_list += f"   - **ä¿®å¤çŠ¶æ€**ï¼šå¾…ä¿®å¤\n\n"
    else:
        fix_list += "\nâœ… æ— å…ƒæ•°æ®é—®é¢˜\n\n"
    
    fix_list += f"""
### æ–‡ä»¶å¼•ç”¨ä¿®å¤
"""
    
    ref_files = [f for f in p1_files if any(issue.get('type') == 'missing_reference' for issue in f['issues'])]
    if ref_files:
        fix_list += f"\n**å…± {len(ref_files)} ä¸ªæ–‡ä»¶éœ€è¦ä¿®å¤æ–‡ä»¶å¼•ç”¨ï¼š**\n\n"
        for i, file_entry in enumerate(ref_files[:20], 1):
            fix_list += f"{i}. **æ–‡ä»¶**ï¼š`{file_entry['path']}`\n"
            fix_list += f"   - **ä¿®å¤çŠ¶æ€**ï¼šå¾…ä¿®å¤\n\n"
    else:
        fix_list += "\nâœ… æ— æ–‡ä»¶å¼•ç”¨é—®é¢˜\n\n"
    
    fix_list += f"""
---

## ğŸ“‹ P2çº§åˆ«ä¿®å¤æ¸…å•ï¼ˆæœ¬æœˆä¿®å¤ï¼‰

### ç‰ˆæœ¬å†²çªå¤„ç†
"""
    
    version_files = [f for f in p2_files if any(issue.get('type') == 'version_conflict' for issue in f['issues'])]
    if version_files:
        fix_list += f"\n**å…± {len(version_files)} ä¸ªæ–‡ä»¶éœ€è¦å¤„ç†ç‰ˆæœ¬å†²çªï¼š**\n\n"
        for i, file_entry in enumerate(version_files[:10], 1):
            fix_list += f"{i}. **æ–‡ä»¶**ï¼š`{file_entry['path']}`\n"
            fix_list += f"   - **ä¿®å¤çŠ¶æ€**ï¼šå¾…ä¿®å¤\n\n"
    else:
        fix_list += "\nâœ… æ— ç‰ˆæœ¬å†²çª\n\n"
    
    fix_list += f"""
---

## ğŸ“Š ä¿®å¤è¿›åº¦

### æ€»ä½“è¿›åº¦
- **æ€»é—®é¢˜æ•°**ï¼š{sum(len(f['issues']) for f in p0_files + p1_files + p2_files)}ä¸ª
- **å·²ä¿®å¤**ï¼š0ä¸ª
- **å¾…ä¿®å¤**ï¼š{sum(len(f['issues']) for f in p0_files + p1_files + p2_files)}ä¸ª
- **ä¿®å¤ç‡**ï¼š0%

### æŒ‰ä¼˜å…ˆçº§
- **P0çº§åˆ«**ï¼š{sum(len(f['issues']) for f in p0_files)}ä¸ªï¼ˆå¾…ä¿®å¤ï¼‰
- **P1çº§åˆ«**ï¼š{sum(len(f['issues']) for f in p1_files)}ä¸ªï¼ˆå¾…ä¿®å¤ï¼‰
- **P2çº§åˆ«**ï¼š{sum(len(f['issues']) for f in p2_files)}ä¸ªï¼ˆå¾…ä¿®å¤ï¼‰

---

**æœ€åæ›´æ–°**ï¼š{date_str}
"""
    
    return fix_list


if __name__ == "__main__":
    main()

