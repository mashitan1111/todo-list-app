#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
AIä¸»åŠ¨é¢„åˆ¤ç³»ç»Ÿ
ç”¨é€”ï¼šAIä¸»åŠ¨é¢„åˆ¤ç”¨æˆ·éœ€æ±‚ï¼Œæå‰å‡†å¤‡æ–¹æ¡ˆ
"""

import json
import re
from datetime import datetime, timedelta
from pathlib import Path

# å·¥ä½œç›®å½•
BASE_DIR = Path(__file__).parent.parent
CONTEXT_FILE = BASE_DIR / "å·¥ä½œè®°å½•ç³»ç»Ÿ" / "å·¥ä½œä¸Šä¸‹æ–‡.md"
TASK_FILE = BASE_DIR / "å·¥ä½œè®°å½•ç³»ç»Ÿ" / "ä»»åŠ¡æ¸…å•.md"
PREDICTION_FILE = BASE_DIR / "å·¥ä½œè®°å½•ç³»ç»Ÿ" / "AIé¢„åˆ¤è®°å½•.md"
PATTERN_FILE = BASE_DIR / "å·¥ä½œè®°å½•ç³»ç»Ÿ" / "é¢„åˆ¤æ¨¡å¼åº“.md"  # æ–°å¢ï¼šé¢„åˆ¤æ¨¡å¼åº“


def read_context():
    """è¯»å–å·¥ä½œä¸Šä¸‹æ–‡"""
    if not CONTEXT_FILE.exists():
        return None
    with open(CONTEXT_FILE, 'r', encoding='utf-8') as f:
        return f.read()


def read_tasks():
    """è¯»å–ä»»åŠ¡æ¸…å•"""
    if not TASK_FILE.exists():
        return None
    with open(TASK_FILE, 'r', encoding='utf-8') as f:
        return f.read()


def analyze_recent_tasks(context_content):
    """åˆ†ææœ€è¿‘å®Œæˆçš„ä»»åŠ¡"""
    # æå–æœ€è¿‘å®Œæˆçš„ä»»åŠ¡
    pattern = r'## âœ… æœ€è¿‘å®Œæˆçš„ä»»åŠ¡\s*\n\s*### (\d{4}-\d{2}-\d{2})\s*\n((?:\d+\. âœ… .*\n)*)'
    match = re.search(pattern, context_content)
    
    if not match:
        return []
    
    tasks = []
    task_lines = match.group(2).strip().split('\n')
    for line in task_lines:
        if 'âœ…' in line:
            task_desc = re.sub(r'^\d+\.\s*âœ…\s*', '', line).strip()
            tasks.append({
                'description': task_desc,
                'date': match.group(1)
            })
    
    return tasks


def analyze_ongoing_tasks(context_content):
    """åˆ†æè¿›è¡Œä¸­çš„ä»»åŠ¡"""
    # æå–è¿›è¡Œä¸­çš„ä»»åŠ¡
    pattern = r'### (P0|P1|P2|P3)çº§åˆ«.*?\n((?:.*?â³.*?\n)*)'
    matches = re.findall(pattern, context_content, re.DOTALL)
    
    tasks = []
    for priority, section in matches:
        # æå–ä»»åŠ¡æè¿°
        task_pattern = r'â³ \*\*(.*?)\*\*'
        task_matches = re.findall(task_pattern, section)
        for task_desc in task_matches:
            tasks.append({
                'description': task_desc,
                'priority': priority,
                'status': 'è¿›è¡Œä¸­'
            })
    
    return tasks


def analyze_pending_tasks(context_content, task_content):
    """åˆ†æå¾…å¤„ç†çš„ä»»åŠ¡"""
    tasks = []
    
    # ä»å·¥ä½œä¸Šä¸‹æ–‡æå–å¾…å¤„ç†ä»»åŠ¡
    pattern = r'## ğŸ“‹ å¾…å¤„ç†ä»»åŠ¡é˜Ÿåˆ—\s*\n(.*?)(?=\n---|\n##)'
    match = re.search(pattern, context_content, re.DOTALL)
    if match:
        task_lines = match.group(1).strip().split('\n')
        for line in task_lines:
            if '- [ ]' in line:
                task_desc = re.sub(r'^- \[ \]\s*', '', line).strip()
                tasks.append({
                    'description': task_desc,
                    'status': 'å¾…å¤„ç†'
                })
    
    # ä»ä»»åŠ¡æ¸…å•æå–å¾…å¤„ç†ä»»åŠ¡
    if task_content:
        pattern = r'- \*\*çŠ¶æ€\*\*ï¼šå¾…å¤„ç†'
        pending_sections = re.findall(r'### (TASK-\d+:.*?)(?=\n### |\n##)', task_content, re.DOTALL)
        for section in pending_sections:
            task_id_match = re.search(r'TASK-\d+', section)
            desc_match = re.search(r'- \*\*æè¿°\*\*ï¼š(.*?)\n', section)
            priority_match = re.search(r'- \*\*ä¼˜å…ˆçº§\*\*ï¼š(P0|P1|P2|P3)', section)
            
            if task_id_match and desc_match:
                tasks.append({
                    'task_id': task_id_match.group(0),
                    'description': desc_match.group(1).strip(),
                    'priority': priority_match.group(1) if priority_match else 'P2',
                    'status': 'å¾…å¤„ç†'
                })
    
    return tasks


def analyze_task_dependencies(task_content):
    """åˆ†æä»»åŠ¡ä¾èµ–å…³ç³»"""
    dependencies = {}
    
    if not task_content:
        return dependencies
    
    # æå–æ‰€æœ‰ä»»åŠ¡
    pattern = r'### (TASK-\d+):(.*?)\n((?:- \*\*.*?\*\*ï¼š.*?\n)*)'
    matches = re.findall(pattern, task_content, re.DOTALL)
    
    for task_id, desc, details in matches:
        # æå–ä¾èµ–ä»»åŠ¡
        dep_match = re.search(r'- \*\*ä¾èµ–ä»»åŠ¡\*\*ï¼š(.*?)\n', details)
        if dep_match:
            dep_str = dep_match.group(1).strip()
            if dep_str and dep_str != 'æ— ':
                dependencies[task_id] = {
                    'description': desc.strip(),
                    'dependencies': dep_str.split('ã€') if 'ã€' in dep_str else [dep_str]
                }
    
    return dependencies


def identify_blocked_tasks(task_content, dependencies):
    """è¯†åˆ«é˜»å¡ä»»åŠ¡"""
    blocked = []
    
    if not task_content:
        return blocked
    
    # æ£€æŸ¥æ¯ä¸ªä»»åŠ¡çš„çŠ¶æ€
    pattern = r'### (TASK-\d+):(.*?)\n((?:- \*\*.*?\*\*ï¼š.*?\n)*)'
    matches = re.findall(pattern, task_content, re.DOTALL)
    
    for task_id, desc, details in matches:
        status_match = re.search(r'- \*\*çŠ¶æ€\*\*ï¼š(.*?)\n', details)
        if status_match and status_match.group(1) == 'å·²é˜»å¡':
            blocked.append({
                'task_id': task_id,
                'description': desc.strip(),
                'reason': 'å·²é˜»å¡'
            })
        
        # æ£€æŸ¥ä¾èµ–ä»»åŠ¡æ˜¯å¦å®Œæˆ
        if task_id in dependencies:
            dep_tasks = dependencies[task_id]['dependencies']
            for dep_task in dep_tasks:
                dep_status = get_task_status(task_content, dep_task.strip())
                if dep_status and dep_status != 'å·²å®Œæˆ':
                    blocked.append({
                        'task_id': task_id,
                        'description': desc.strip(),
                        'reason': f'ä¾èµ–ä»»åŠ¡ {dep_task} æœªå®Œæˆ'
                    })
    
    return blocked


def get_task_status(task_content, task_id):
    """è·å–ä»»åŠ¡çŠ¶æ€"""
    pattern = rf'### {re.escape(task_id)}:.*?\n((?:- \*\*.*?\*\*ï¼š.*?\n)*)'
    match = re.search(pattern, task_content)
    if match:
        status_match = re.search(r'- \*\*çŠ¶æ€\*\*ï¼š(.*?)\n', match.group(1))
        if status_match:
            return status_match.group(1).strip()
    return None


def predict_next_tasks(context_content, task_content):
    """é¢„æµ‹ä¸‹ä¸€æ­¥ä»»åŠ¡"""
    predictions = []
    
    # 1. åˆ†æé˜»å¡ä»»åŠ¡
    dependencies = analyze_task_dependencies(task_content)
    blocked_tasks = identify_blocked_tasks(task_content, dependencies)
    
    if blocked_tasks:
        predictions.append({
            'type': 'blocked',
            'priority': 'P0',
            'message': f'å‘ç° {len(blocked_tasks)} ä¸ªé˜»å¡ä»»åŠ¡ï¼Œå»ºè®®ä¼˜å…ˆå¤„ç†',
            'tasks': blocked_tasks[:3]  # åªæ˜¾ç¤ºå‰3ä¸ª
        })
    
    # 2. åˆ†æP0çº§åˆ«å¾…å¤„ç†ä»»åŠ¡
    pending_tasks = analyze_pending_tasks(context_content, task_content)
    p0_tasks = [t for t in pending_tasks if t.get('priority') == 'P0']
    
    if p0_tasks:
        predictions.append({
            'type': 'p0_pending',
            'priority': 'P0',
            'message': f'å‘ç° {len(p0_tasks)} ä¸ªP0çº§åˆ«å¾…å¤„ç†ä»»åŠ¡',
            'tasks': p0_tasks[:3]
        })
    
    # 3. åˆ†æP1çº§åˆ«å¾…å¤„ç†ä»»åŠ¡
    p1_tasks = [t for t in pending_tasks if t.get('priority') == 'P1']
    
    if p1_tasks:
        predictions.append({
            'type': 'p1_pending',
            'priority': 'P1',
            'message': f'å‘ç° {len(p1_tasks)} ä¸ªP1çº§åˆ«å¾…å¤„ç†ä»»åŠ¡',
            'tasks': p1_tasks[:3]
        })
    
    # 4. åˆ†æè¿›è¡Œä¸­çš„ä»»åŠ¡
    ongoing_tasks = analyze_ongoing_tasks(context_content)
    
    if ongoing_tasks:
        predictions.append({
            'type': 'ongoing',
            'priority': 'P1',
            'message': f'å‘ç° {len(ongoing_tasks)} ä¸ªè¿›è¡Œä¸­çš„ä»»åŠ¡',
            'tasks': ongoing_tasks[:3]
        })
    
    return predictions


def generate_prediction_report(predictions):
    """ç”Ÿæˆé¢„åˆ¤æŠ¥å‘Š"""
    report = "# AIä¸»åŠ¨é¢„åˆ¤æŠ¥å‘Š\n\n"
    report += f"## ã€å…ƒæ•°æ®ã€‘\n"
    report += f"- **é¢„åˆ¤æ—¶é—´**ï¼š{datetime.now().strftime('%Y-%m-%d %H:%M')}\n"
    report += f"- **é¢„åˆ¤æ•°é‡**ï¼š{len(predictions)}ä¸ª\n"
    report += f"- **ç‰ˆæœ¬**ï¼šV1.0\n\n"
    report += "---\n\n"
    
    if not predictions:
        report += "## âœ… å½“å‰çŠ¶æ€è‰¯å¥½\n\n"
        report += "æœªå‘ç°éœ€è¦ç«‹å³å¤„ç†çš„ä»»åŠ¡ã€‚\n"
        return report
    
    report += "## ğŸ¯ é¢„åˆ¤ç»“æœ\n\n"
    
    for i, pred in enumerate(predictions, 1):
        priority_icon = {
            'P0': 'ğŸš¨',
            'P1': 'âš¡',
            'P2': 'ğŸ“',
            'P3': 'ğŸ“‹'
        }.get(pred['priority'], 'ğŸ“‹')
        
        report += f"### {i}. {priority_icon} {pred['message']}\n\n"
        
        if 'tasks' in pred and pred['tasks']:
            report += "**ç›¸å…³ä»»åŠ¡**ï¼š\n"
            for task in pred['tasks']:
                task_id = task.get('task_id', '')
                desc = task.get('description', '')
                if task_id:
                    report += f"- `{task_id}`: {desc}\n"
                else:
                    report += f"- {desc}\n"
            report += "\n"
        
        # æ ¹æ®ç±»å‹æä¾›å»ºè®®
        if pred['type'] == 'blocked':
            report += "**å»ºè®®**ï¼šä¼˜å…ˆå¤„ç†é˜»å¡ä»»åŠ¡ï¼Œè§£é™¤é˜»å¡åå¯ä»¥ç»§ç»­æ‰§è¡Œåç»­ä»»åŠ¡ã€‚\n\n"
        elif pred['type'] == 'p0_pending':
            report += "**å»ºè®®**ï¼šç«‹å³å¤„ç†P0çº§åˆ«ä»»åŠ¡ï¼Œè¿™äº›æ˜¯é˜»å¡æ€§é—®é¢˜ã€‚\n\n"
        elif pred['type'] == 'p1_pending':
            report += "**å»ºè®®**ï¼šå°½å¿«å¤„ç†P1çº§åˆ«ä»»åŠ¡ï¼Œè¿™äº›æ˜¯é‡è¦é—®é¢˜ã€‚\n\n"
        elif pred['type'] == 'ongoing':
            report += "**å»ºè®®**ï¼šç»§ç»­æ¨è¿›è¿›è¡Œä¸­çš„ä»»åŠ¡ï¼Œç¡®ä¿æŒ‰æ—¶å®Œæˆã€‚\n\n"
    
    report += "---\n\n"
    report += "**æœ€åæ›´æ–°**ï¼š" + datetime.now().strftime('%Y-%m-%d %H:%M') + "\n"
    
    return report


def save_prediction(predictions):
    """ä¿å­˜é¢„åˆ¤ç»“æœ"""
    report = generate_prediction_report(predictions)
    
    with open(PREDICTION_FILE, 'w', encoding='utf-8') as f:
        f.write(report)
    
    print(f"âœ… å·²ä¿å­˜é¢„åˆ¤æŠ¥å‘Šï¼š{PREDICTION_FILE}")
    return report


def generate_suggestions(predictions):
    """ç”Ÿæˆå»ºè®®æ–¹æ¡ˆ"""
    suggestions = []
    
    for pred in predictions:
        if pred['type'] == 'blocked':
            suggestions.append({
                'action': 'å¤„ç†é˜»å¡ä»»åŠ¡',
                'tasks': [t.get('task_id') or t.get('description') for t in pred.get('tasks', [])],
                'priority': 'P0'
            })
        elif pred['type'] == 'p0_pending':
            suggestions.append({
                'action': 'å¤„ç†P0çº§åˆ«ä»»åŠ¡',
                'tasks': [t.get('task_id') or t.get('description') for t in pred.get('tasks', [])],
                'priority': 'P0'
            })
        elif pred['type'] == 'p1_pending':
            suggestions.append({
                'action': 'å¤„ç†P1çº§åˆ«ä»»åŠ¡',
                'tasks': [t.get('task_id') or t.get('description') for t in pred.get('tasks', [])],
                'priority': 'P1'
            })
    
    return suggestions


def load_prediction_patterns():
    """åŠ è½½é¢„åˆ¤æ¨¡å¼åº“ï¼ˆæ–°å¢ - V4.0æ•ˆç‡ä¼˜åŒ–ï¼‰"""
    if not PATTERN_FILE.exists():
        return {}
    
    patterns = {}
    with open(PATTERN_FILE, 'r', encoding='utf-8') as f:
        content = f.read()
    
    # æå–å†å²æ¨¡å¼
    pattern_sections = re.findall(r'### æ¨¡å¼\d+\.\d+ï¼š(.*?)\n(.*?)(?=\n### |\n##)', content, re.DOTALL)
    for pattern_name, pattern_content in pattern_sections:
        # æå–å‡†ç¡®ç‡
        accuracy_match = re.search(r'\*\*å‡†ç¡®ç‡\*\*ï¼š(\d+)%', pattern_content)
        accuracy = int(accuracy_match.group(1)) if accuracy_match else 0
        
        # æå–é¢„åˆ¤è§„åˆ™
        rules_match = re.search(r'\*\*é¢„åˆ¤è§„åˆ™\*\*ï¼š\n((?:- .*\n)*)', pattern_content)
        rules = []
        if rules_match:
            rule_lines = rules_match.group(1).strip().split('\n')
            for line in rule_lines:
                if line.startswith('- '):
                    rules.append(line[2:].strip())
        
        patterns[pattern_name.strip()] = {
            'accuracy': accuracy,
            'rules': rules,
            'content': pattern_content
        }
    
    return patterns

def predict_user_needs():
    """é¢„åˆ¤ç”¨æˆ·éœ€æ±‚ï¼ˆå¢å¼ºç‰ˆ - é›†æˆé¢„åˆ¤æ¨¡å¼åº“ï¼‰"""
    print("ğŸ” å¼€å§‹åˆ†æå·¥ä½œä¸Šä¸‹æ–‡å’Œä»»åŠ¡æ¸…å•...")
    
    # åŠ è½½é¢„åˆ¤æ¨¡å¼åº“
    print("ğŸ“š åŠ è½½é¢„åˆ¤æ¨¡å¼åº“...")
    patterns = load_prediction_patterns()
    print(f"   åŠ è½½ {len(patterns)} ä¸ªé¢„åˆ¤æ¨¡å¼")
    
    # è¯»å–æ–‡ä»¶
    context_content = read_context()
    task_content = read_tasks()
    
    if not context_content:
        print("âŒ é”™è¯¯ï¼šæ‰¾ä¸åˆ°å·¥ä½œä¸Šä¸‹æ–‡æ–‡ä»¶")
        return None
    
    # åˆ†æ
    print("ğŸ“Š åˆ†ææœ€è¿‘å®Œæˆçš„ä»»åŠ¡...")
    recent_tasks = analyze_recent_tasks(context_content)
    print(f"   å‘ç° {len(recent_tasks)} ä¸ªæœ€è¿‘å®Œæˆçš„ä»»åŠ¡")
    
    print("ğŸ“Š åˆ†æè¿›è¡Œä¸­çš„ä»»åŠ¡...")
    ongoing_tasks = analyze_ongoing_tasks(context_content)
    print(f"   å‘ç° {len(ongoing_tasks)} ä¸ªè¿›è¡Œä¸­çš„ä»»åŠ¡")
    
    print("ğŸ“Š åˆ†æå¾…å¤„ç†çš„ä»»åŠ¡...")
    pending_tasks = analyze_pending_tasks(context_content, task_content)
    print(f"   å‘ç° {len(pending_tasks)} ä¸ªå¾…å¤„ç†çš„ä»»åŠ¡")
    
    print("ğŸ“Š åˆ†æä»»åŠ¡ä¾èµ–å…³ç³»...")
    dependencies = analyze_task_dependencies(task_content)
    print(f"   å‘ç° {len(dependencies)} ä¸ªä»»åŠ¡æœ‰ä¾èµ–å…³ç³»")
    
    print("ğŸ“Š è¯†åˆ«é˜»å¡ä»»åŠ¡...")
    blocked_tasks = identify_blocked_tasks(task_content, dependencies)
    print(f"   å‘ç° {len(blocked_tasks)} ä¸ªé˜»å¡ä»»åŠ¡")
    
    # é¢„æµ‹ï¼ˆå¢å¼ºï¼šç»“åˆé¢„åˆ¤æ¨¡å¼åº“ï¼‰
    print("ğŸ¯ é¢„æµ‹ä¸‹ä¸€æ­¥ä»»åŠ¡ï¼ˆç»“åˆé¢„åˆ¤æ¨¡å¼åº“ï¼‰...")
    predictions = predict_next_tasks(context_content, task_content)
    
    # åº”ç”¨é¢„åˆ¤æ¨¡å¼åº“è§„åˆ™ï¼ˆå¢å¼ºé¢„åˆ¤å‡†ç¡®æ€§ï¼‰
    if patterns:
        print("ğŸ“Š åº”ç”¨é¢„åˆ¤æ¨¡å¼åº“è§„åˆ™...")
        enhanced_predictions = []
        for pred in predictions:
            # æ ¹æ®æ¨¡å¼åº“è°ƒæ•´é¢„åˆ¤ä¼˜å…ˆçº§å’Œå‡†ç¡®æ€§
            for pattern_name, pattern_data in patterns.items():
                if pattern_data['accuracy'] >= 80:  # åªä½¿ç”¨é«˜å‡†ç¡®ç‡æ¨¡å¼
                    # æ£€æŸ¥é¢„åˆ¤æ˜¯å¦åŒ¹é…æ¨¡å¼
                    if any(rule in str(pred) for rule in pattern_data['rules']):
                        pred['pattern_matched'] = pattern_name
                        pred['confidence'] = pattern_data['accuracy'] / 100
                        break
            enhanced_predictions.append(pred)
        predictions = enhanced_predictions
    
    print(f"   ç”Ÿæˆ {len(predictions)} ä¸ªé¢„åˆ¤ç»“æœ")
    
    # ç”Ÿæˆå»ºè®®
    suggestions = generate_suggestions(predictions)
    
    # ä¿å­˜é¢„åˆ¤ç»“æœ
    report = save_prediction(predictions)
    
    # è¾“å‡ºé¢„åˆ¤ç»“æœ
    print("\n" + "="*60)
    print("AIä¸»åŠ¨é¢„åˆ¤ç»“æœ")
    print("="*60)
    print(report)
    
    return {
        'predictions': predictions,
        'suggestions': suggestions,
        'report': report
    }


if __name__ == "__main__":
    predict_user_needs()

